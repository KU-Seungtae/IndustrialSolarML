{"cells":[{"cell_type":"markdown","metadata":{"id":"0Tc7zXpI5qff"},"source":["# Actual vs Predicted"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F0YfhnLZ5qfg"},"outputs":[],"source":["import os\n","import joblib\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Create output directory\n","os.makedirs(\"Actual_predicted\", exist_ok=True)\n","\n","# Load and preprocess dataset\n","data = pd.read_excel(\"multiwafer_database.xlsx\")\n","data.columns = data.columns.str.replace(\" \", \"_\")\n","\n","# Define input features\n","features = [\n","    'P01', 'P02', 'P03', 'P04', 'P05', 'P06', 'Tester',\n","    'Dark_Area_%', 'Defect_Area_%', 'Grain_Defect_Area_%',\n","    'Average_Life_Time', 'Sigma_Life_Time',\n","    'Resistivity', 'Wafer_Area', 'Vendor_name'\n","]\n","X = data[features]\n","\n","# Define target variables and corresponding model paths\n","target_model_info = {\n","    \"Voc\": \"../1. Training/(Voc)best_model_GBR.pkl\",\n","    \"Isc\": \"../1. Training/(Isc)best_model_XGB.pkl\",\n","    \"FF\": \"../1. Training/(FF)best_model_XGB.pkl\",\n","    \"Efficiency\": \"../1. Training/(Efficiency)best_model_ET.pkl\"\n","}\n","\n","for target, model_path in target_model_info.items():\n","    y = data[target]\n","\n","    # Split: 60% training, 20% validation, 20% test\n","    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n","    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","    # Combine training and validation sets for final model inference\n","    X_train_val = pd.concat([X_train, X_val])\n","    y_train_val = pd.concat([y_train, y_val])\n","\n","    # Load trained model and perform inference\n","    model = joblib.load(model_path)\n","    pred_train_val = model.predict(X_train_val)\n","    pred_test = model.predict(X_test)\n","\n","    # Export actual vs. predicted values\n","    with pd.ExcelWriter(f\"Actual_predicted/{target}_Actual_vs_Predicted.xlsx\") as writer:\n","        pd.DataFrame({\n","            \"Actual\": y_train_val.values,\n","            \"Predicted\": pred_train_val\n","        }).to_excel(writer, sheet_name=\"Training_and_Validation\", index=False)\n","\n","        pd.DataFrame({\n","            \"Actual\": y_test.values,\n","            \"Predicted\": pred_test\n","        }).to_excel(writer, sheet_name=\"Test\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gvLQDpG55qfi","outputId":"75655948-be65-42bd-f5b7-05f393c57c3f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Normalized file saved to: Actual_predicted/Efficiency_Actual_vs_Predicted_Normalized.xlsx\n"]}],"source":["# Normalization\n","\n","import pandas as pd\n","\n","# File paths\n","db_path = \"multiwafer_database.xlsx\"\n","input_path = \"Actual_predicted/Efficiency_Actual_vs_Predicted.xlsx\"\n","output_path = \"Actual_predicted/Efficiency_Actual_vs_Predicted_Normalized.xlsx\"\n","\n","# Load Efficiency range from database\n","eff_data = pd.read_excel(db_path)\n","eff_min = eff_data[\"Efficiency\"].min()\n","eff_max = eff_data[\"Efficiency\"].max()\n","\n","# Target sheet names\n","sheets_to_normalize = [\"Training_and_Validation\", \"Test\"]\n","normalized_sheets = {}\n","\n","# Normalize each sheet separately\n","for sheet in sheets_to_normalize:\n","    df = pd.read_excel(input_path, sheet_name=sheet)\n","    df_norm = df.copy()\n","    for col in df.columns:\n","        if pd.api.types.is_numeric_dtype(df[col]):\n","            df_norm[col] = (df[col] - eff_min) / (eff_max - eff_min)\n","    normalized_sheets[sheet] = df_norm\n","\n","# Save normalized sheets to one Excel file\n","with pd.ExcelWriter(output_path) as writer:\n","    for sheet_name, df_norm in normalized_sheets.items():\n","        df_norm.to_excel(writer, sheet_name=sheet_name, index=False)\n","\n","print(f\"Normalized file saved to: {output_path}\")"]},{"cell_type":"markdown","metadata":{"id":"xICTyYWh5qfk"},"source":["# SHAP analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wQV1XJCH5qfl"},"outputs":[],"source":["import os\n","import joblib\n","import shap\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Output directory\n","os.makedirs(\"SHAP\", exist_ok=True)\n","\n","# Load dataset\n","data = pd.read_excel(\"multiwafer_database.xlsx\")\n","data.columns = data.columns.str.replace(\" \", \"_\")\n","\n","# Input features\n","features = [\n","    'P01', 'P02', 'P03', 'P04', 'P05', 'P06', 'Tester',\n","    'Dark_Area_%', 'Defect_Area_%', 'Grain_Defect_Area_%',\n","    'Average_Life_Time', 'Sigma_Life_Time',\n","    'Resistivity', 'Wafer_Area', 'Vendor_name'\n","]\n","X = data[features]\n","y = data[\"Efficiency\"]\n","\n","# Data split\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","# Load model\n","model = joblib.load(\"../1. Training/(Efficiency)best_model_ET.pkl\")\n","\n","# SHAP computation\n","explainer = shap.Explainer(model)\n","shap_values = explainer(X_test)\n","\n","# Save SHAP dependence data\n","records = []\n","for i, feature in enumerate(X_test.columns):\n","    records.append(pd.DataFrame({\n","        \"Feature\": feature,\n","        \"Feature_Value\": X_test.iloc[:, i].values,\n","        \"SHAP_Value\": shap_values.values[:, i]\n","    }))\n","\n","pd.concat(records, ignore_index=True).to_csv(\"SHAP/SHAP_dependence_Efficiency.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"tPSebsZt5qfl"},"source":["# Feature Importance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cQg7pIQm5qfl","outputId":"4c563919-1643-497b-8051-3098afea8bcb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing target: Voc\n","Processing target: Isc\n","Processing target: FF\n","Processing target: Efficiency\n","Feature importance and SHAP summary saved.\n"]}],"source":["import os\n","import joblib\n","import shap\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","# Output directory\n","output_dir = \"SHAP\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Load dataset\n","data = pd.read_excel(\"multiwafer_database.xlsx\")\n","data.columns = data.columns.str.replace(\" \", \"_\")\n","\n","# Input features\n","input_features = [\n","    'P01', 'P02', 'P03', 'P04', 'P05', 'P06', 'Tester',\n","    'Dark_Area_%', 'Defect_Area_%', 'Grain_Defect_Area_%',\n","    'Average_Life_Time', 'Sigma_Life_Time',\n","    'Resistivity', 'Wafer_Area', 'Vendor_name'\n","]\n","X = data[input_features]\n","\n","# Target names and corresponding model paths\n","targets = [\"Voc\", \"Isc\", \"FF\", \"Efficiency\"]\n","model_paths = {\n","    \"Voc\": \"../1. Training/(Voc)best_model_GBR.pkl\",\n","    \"Isc\": \"../1. Training/(Isc)best_model_XGB.pkl\",\n","    \"FF\": \"../1. Training/(FF)best_model_XGB.pkl\",\n","    \"Efficiency\": \"../1. Training/(Efficiency)best_model_ET.pkl\"\n","}\n","\n","importance_dfs = []\n","shap_summary_df = None\n","\n","for target in targets:\n","    print(f\"Processing target: {target}\")\n","    y = data[target]\n","\n","    # Split: 60% training, 20% validation, 20% test\n","    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n","    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","    # Load model\n","    model = joblib.load(model_paths[target])\n","\n","    # Feature importance\n","    importance = model.feature_importances_\n","    df_importance = pd.DataFrame({\n","        \"Target\": target,\n","        \"Feature\": X.columns,\n","        \"Importance\": importance\n","    })\n","    importance_dfs.append(df_importance)\n","\n","    # SHAP analysis (Efficiency only)\n","    if target == \"Efficiency\":\n","        explainer = shap.TreeExplainer(model)\n","        shap_values = explainer.shap_values(X_test)\n","        df_shap = pd.DataFrame({\n","            \"Feature\": X.columns,\n","            \"Mean_SHAP_Value\": np.abs(shap_values).mean(axis=0)\n","        }).sort_values(by=\"Mean_SHAP_Value\", ascending=False)\n","        shap_summary_df = df_shap\n","\n","# Save feature importance\n","all_importance_df = pd.concat(importance_dfs, ignore_index=True)\n","all_importance_df.to_excel(os.path.join(output_dir, \"Feature_Importance_All_Models.xlsx\"), index=False)\n","\n","# Save SHAP results\n","if shap_summary_df is not None:\n","    shap_summary_df.to_excel(os.path.join(output_dir, \"Efficiency_Average_SHAP_Values.xlsx\"), index=False)\n","\n","print(\"Feature importance and SHAP summary saved.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ProKlGED5qfm"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"250605_multiwafer","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}