{"cells":[{"cell_type":"markdown","metadata":{"id":"JXvgh8Zm6xtq"},"source":["# Top 1% Path Extraction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ztfFtWp6xtr"},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","\n","# Output directory\n","output_dir = \"additional_analysis\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Load data\n","data = pd.read_excel(\"multiwafer_database.xlsx\")\n","data.columns = data.columns.str.replace(\" \", \"_\")\n","\n","# Path features\n","path_features = ['P01', 'P02', 'P03', 'P04', 'P05', 'P06', 'Tester']\n","\n","# Top 1% by efficiency\n","threshold_top = np.percentile(data[\"Efficiency\"], 99)\n","top_samples = data[data[\"Efficiency\"] >= threshold_top]\n","\n","# Save\n","top_paths = top_samples[path_features]\n","top_paths.to_excel(os.path.join(output_dir, \"Top_1pct_Paths.xlsx\"), index=False)"]},{"cell_type":"markdown","metadata":{"id":"DQZtmX6q6xts"},"source":["# Bottom 1% Path Extraction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WM4ZEN6E6xts"},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","\n","# Output directory\n","output_dir = \"additional_analysis\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Load data\n","data = pd.read_excel(\"multiwafer_database.xlsx\")\n","data.columns = data.columns.str.replace(\" \", \"_\")\n","\n","# Path features\n","path_features = ['P01', 'P02', 'P03', 'P04', 'P05', 'P06', 'Tester']\n","\n","# Bottom 1% by efficiency\n","threshold_bottom = np.percentile(data[\"Efficiency\"], 1)\n","bottom_samples = data[data[\"Efficiency\"] <= threshold_bottom]\n","\n","# Save\n","bottom_paths = bottom_samples[path_features]\n","bottom_paths.to_excel(os.path.join(output_dir, \"Bottom_1pct_Paths.xlsx\"), index=False)"]},{"cell_type":"markdown","metadata":{"id":"n_kSqzy76xts"},"source":["# Cluster-Based Optimization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNYjbeHA6xtt","outputId":"d85de5f4-111f-47ed-a395-c78d26aa0d69"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved cluster 498 to sheet 'Cluster_498'\n","Saved cluster 422 to sheet 'Cluster_422'\n","Saved cluster 465 to sheet 'Cluster_465'\n","Saved cluster 319 to sheet 'Cluster_319'\n","Saved cluster 29 to sheet 'Cluster_29'\n","Saved cluster 218 to sheet 'Cluster_218'\n","Saved cluster 651 to sheet 'Cluster_651'\n","Saved cluster 540 to sheet 'Cluster_540'\n","Saved cluster 917 to sheet 'Cluster_917'\n","Saved cluster 321 to sheet 'Cluster_321'\n","\n","All results saved to: additional_analysis/Cluster_Optimization_Result_low.xlsx\n"]}],"source":["import os\n","import time\n","import joblib\n","import numpy as np\n","import pandas as pd\n","import optuna\n","from datetime import timedelta\n","\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","\n","RANDOM_STATE = 42\n","np.random.seed(RANDOM_STATE)\n","\n","output_dir = \"additional_analysis\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Load dataset and trained model\n","data = pd.read_excel(\"multiwafer_database.xlsx\")\n","data.columns = data.columns.str.replace(\" \", \"_\")\n","model = joblib.load(\"../1. Training/(Efficiency)best_model_ET.pkl\")\n","\n","# Define feature sets\n","equipment_features = ['P02', 'P03', 'P04', 'P05', 'P06', 'Tester']\n","quality_features = [\n","    'P01', 'Dark_Area_%', 'Defect_Area_%', 'Grain_Defect_Area_%',\n","    'Average_Life_Time', 'Sigma_Life_Time',\n","    'Resistivity', 'Wafer_Area', 'Vendor_name'\n","]\n","trained_features = model.feature_names_in_\n","\n","# Define hyperparameter search space\n","param_ranges = {\n","    'P02': (1, 6), 'P03': (1, 15),\n","    'P04': (1, 6), 'P05': (1, 15),\n","    'P06': (1, 27), 'Tester': (1, 20)\n","}\n","\n","# Select 10 clusters with lowest average efficiency\n","cluster_means = data.groupby(\"Cluster\")[\"Efficiency\"].mean().sort_values()\n","low_clusters = cluster_means.head(100).index\n","selected_clusters = np.random.choice(low_clusters, size=10, replace=False)\n","\n","# Optimize samples from each selected cluster and save results per sheet\n","output_file = os.path.join(output_dir, \"Cluster_Optimization_Result_low.xlsx\")\n","with pd.ExcelWriter(output_file, engine=\"openpyxl\") as writer:\n","    for selected_cluster in selected_clusters:\n","        cluster_data = data[data[\"Cluster\"] == selected_cluster]\n","        cluster_results = []\n","\n","        for idx, row in cluster_data.iterrows():\n","            quality_values = row[quality_features]\n","            initial_eff = row[\"Efficiency\"]\n","            initial_path = {key: row[key] for key in equipment_features}\n","\n","            def objective(trial):\n","                path = {key: trial.suggest_int(key, *param_ranges[key]) for key in equipment_features}\n","                full_input = {**path, **quality_values.to_dict()}\n","                input_df = pd.DataFrame([full_input])[trained_features]\n","                return model.predict(input_df)[0]\n","\n","            start = time.time()\n","            study = optuna.create_study(\n","                direction=\"maximize\",\n","                sampler=optuna.samplers.TPESampler(n_startup_trials=20, seed=RANDOM_STATE)\n","            )\n","            study.optimize(objective, n_trials=300)\n","            elapsed = time.time() - start\n","\n","            best_path = study.best_params\n","            result_row = {\n","                \"Selected Cluster\": selected_cluster,\n","                \"Sample Index\": idx,\n","                \"Initial Efficiency\": initial_eff,\n","                \"Optimized Efficiency\": study.best_value,\n","                \"Elapsed Time\": str(timedelta(seconds=int(elapsed)))\n","            }\n","            for key in equipment_features:\n","                result_row[f\"Initial_{key}\"] = initial_path[key]\n","                result_row[f\"Best_{key}\"] = best_path[key]\n","\n","            cluster_results.append(result_row)\n","\n","        df_cluster = pd.DataFrame(cluster_results)\n","        sheet_name = f\"Cluster_{selected_cluster}\"[:31]\n","        df_cluster.to_excel(writer, sheet_name=sheet_name, index=False)\n","        print(f\"Saved cluster {selected_cluster} to sheet '{sheet_name}'\")\n","\n","print(f\"\\nAll results saved to: {output_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wVi3ECcI6xtt","outputId":"460317a7-088b-45b6-aa13-ad60352f7541"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved cluster 15 to sheet 'Cluster_15'\n","Saved cluster 118 to sheet 'Cluster_118'\n","Saved cluster 143 to sheet 'Cluster_143'\n","Saved cluster 206 to sheet 'Cluster_206'\n","Saved cluster 89 to sheet 'Cluster_89'\n","Saved cluster 264 to sheet 'Cluster_264'\n","Saved cluster 983 to sheet 'Cluster_983'\n","Saved cluster 5 to sheet 'Cluster_5'\n","Saved cluster 311 to sheet 'Cluster_311'\n","Saved cluster 956 to sheet 'Cluster_956'\n","\n","All results saved to: additional_analysis/Cluster_Optimization_Result.xlsx\n"]}],"source":["import os\n","import time\n","import joblib\n","import numpy as np\n","import pandas as pd\n","import optuna\n","from datetime import timedelta\n","\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","\n","RANDOM_STATE = 42\n","np.random.seed(RANDOM_STATE)\n","\n","output_dir = \"additional_analysis\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Load dataset and trained model\n","data = pd.read_excel(\"multiwafer_database.xlsx\")\n","data.columns = data.columns.str.replace(\" \", \"_\")\n","model = joblib.load(\"../1. Training/(Efficiency)best_model_ET.pkl\")\n","\n","# Define feature sets\n","equipment_features = ['P02', 'P03', 'P04', 'P05', 'P06', 'Tester']\n","quality_features = [\n","    'P01', 'Dark_Area_%', 'Defect_Area_%', 'Grain_Defect_Area_%',\n","    'Average_Life_Time', 'Sigma_Life_Time',\n","    'Resistivity', 'Wafer_Area', 'Vendor_name'\n","]\n","trained_features = model.feature_names_in_\n","\n","# Define hyperparameter search space\n","param_ranges = {\n","    'P02': (1, 6), 'P03': (1, 15),\n","    'P04': (1, 6), 'P05': (1, 15),\n","    'P06': (1, 27), 'Tester': (1, 20)\n","}\n","\n","# Randomly select 10 clusters from all available clusters\n","all_clusters = data[\"Cluster\"].unique()\n","selected_clusters = np.random.choice(all_clusters, size=10, replace=False)\n","\n","# Optimize samples from each selected cluster and save results per sheet\n","output_file = os.path.join(output_dir, \"Cluster_Optimization_Result.xlsx\")\n","with pd.ExcelWriter(output_file, engine=\"openpyxl\") as writer:\n","    for selected_cluster in selected_clusters:\n","        cluster_data = data[data[\"Cluster\"] == selected_cluster]\n","        cluster_results = []\n","\n","        for idx, row in cluster_data.iterrows():\n","            quality_values = row[quality_features]\n","            initial_eff = row[\"Efficiency\"]\n","            initial_path = {key: row[key] for key in equipment_features}\n","\n","            def objective(trial):\n","                path = {key: trial.suggest_int(key, *param_ranges[key]) for key in equipment_features}\n","                full_input = {**path, **quality_values.to_dict()}\n","                input_df = pd.DataFrame([full_input])[trained_features]\n","                return model.predict(input_df)[0]\n","\n","            start = time.time()\n","            study = optuna.create_study(\n","                direction=\"maximize\",\n","                sampler=optuna.samplers.TPESampler(n_startup_trials=20, seed=RANDOM_STATE)\n","            )\n","            study.optimize(objective, n_trials=300)\n","            elapsed = time.time() - start\n","\n","            best_path = study.best_params\n","            result_row = {\n","                \"Selected Cluster\": selected_cluster,\n","                \"Sample Index\": idx,\n","                \"Initial Efficiency\": initial_eff,\n","                \"Optimized Efficiency\": study.best_value,\n","                \"Elapsed Time\": str(timedelta(seconds=int(elapsed)))\n","            }\n","            for key in equipment_features:\n","                result_row[f\"Initial_{key}\"] = initial_path[key]\n","                result_row[f\"Best_{key}\"] = best_path[key]\n","\n","            cluster_results.append(result_row)\n","\n","        df_cluster = pd.DataFrame(cluster_results)\n","        sheet_name = f\"Cluster_{selected_cluster}\"[:31]\n","        df_cluster.to_excel(writer, sheet_name=sheet_name, index=False)\n","        print(f\"Saved cluster {selected_cluster} to sheet '{sheet_name}'\")\n","\n","print(f\"\\nAll results saved to: {output_file}\")"]},{"cell_type":"markdown","metadata":{"id":"ok0NOq-O6xtt"},"source":["# Pathwise Efficiency Contribution Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_iewdV7t6xtu"},"outputs":[],"source":["import os\n","import time\n","import joblib\n","import numpy as np\n","import pandas as pd\n","import optuna\n","from datetime import timedelta\n","\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","\n","data = pd.read_excel(\"multiwafer_database.xlsx\")\n","data.columns = data.columns.str.replace(\" \", \"_\")\n","model = joblib.load(\"../1. Training/(Efficiency)best_model_ET.pkl\")\n","\n","RANDOM_STATE = 42\n","np.random.seed(RANDOM_STATE)\n","\n","equipment_features = ['P02', 'P03', 'P04', 'P05', 'P06', 'Tester']\n","quality_features = [\n","    'P01', 'Dark_Area_%', 'Defect_Area_%', 'Grain_Defect_Area_%',\n","    'Average_Life_Time', 'Sigma_Life_Time',\n","    'Resistivity', 'Wafer_Area', 'Vendor_name'\n","]\n","trained_features = model.feature_names_in_\n","\n","param_ranges = {\n","    'P02': (1, 6), 'P03': (1, 15),\n","    'P04': (1, 6), 'P05': (1, 15), 'P06': (1, 27),\n","    'Tester': (1, 20)\n","}\n","\n","# Select bottom 0.25% samples\n","threshold = np.percentile(data[\"Efficiency\"], 0.25)\n","samples = data[data[\"Efficiency\"] <= threshold].sample(n=100, random_state=RANDOM_STATE)\n","\n","results = []\n","\n","for idx, sample in samples.iterrows():\n","    quality_values = sample[quality_features]\n","    initial_eff = sample[\"Efficiency\"]\n","    initial_path = {key: sample[key] for key in equipment_features}\n","\n","    def objective(trial):\n","        path = {key: trial.suggest_int(key, *param_ranges[key]) for key in equipment_features}\n","        full_input = {**path, **quality_values.to_dict()}\n","        input_df = pd.DataFrame([full_input])[trained_features]\n","        return model.predict(input_df)[0]\n","\n","    study = optuna.create_study(\n","        direction=\"maximize\",\n","        sampler=optuna.samplers.TPESampler(n_startup_trials=20, seed=RANDOM_STATE)\n","    )\n","    start = time.time()\n","    study.optimize(objective, n_trials=300)\n","    elapsed = time.time() - start\n","\n","    best_path = study.best_params\n","    optimized_input = {**best_path, **quality_values.to_dict()}\n","    E_optimized = model.predict(pd.DataFrame([optimized_input])[trained_features])[0]\n","\n","    row = {\n","        \"Data Point\": idx,\n","        \"Initial Efficiency\": initial_eff,\n","        \"Optimized Efficiency\": E_optimized,\n","        \"Elapsed Time\": str(timedelta(seconds=int(elapsed)))\n","    }\n","\n","    for key in equipment_features:\n","        row[f\"Initial_{key}\"] = initial_path[key]\n","        row[f\"Best_{key}\"] = best_path[key]\n","\n","    for key in equipment_features:\n","        partial_path = initial_path.copy()\n","        partial_path[key] = best_path[key]\n","        partial_input = {**partial_path, **quality_values.to_dict()}\n","        E_partial = model.predict(pd.DataFrame([partial_input])[trained_features])[0]\n","        row[f\"ΔEff_{key}\"] = E_partial - initial_eff\n","\n","    results.append(row)\n","\n","# Save\n","df = pd.DataFrame(results)\n","os.makedirs(\"additional_analysis\", exist_ok=True)\n","df.to_excel(\"additional_analysis/Pathwise_Contribution_Trial1.xlsx\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wq4Jv_4y6xtu"},"outputs":[],"source":["import os\n","import time\n","import joblib\n","import numpy as np\n","import pandas as pd\n","import optuna\n","from datetime import timedelta\n","\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","\n","data = pd.read_excel(\"multiwafer_database.xlsx\")\n","data.columns = data.columns.str.replace(\" \", \"_\")\n","model = joblib.load(\"../1. Training/(Efficiency)best_model_ET.pkl\")\n","\n","RANDOM_STATE = 42\n","np.random.seed(RANDOM_STATE)\n","\n","equipment_features = ['P02', 'P03', 'P04', 'P05', 'P06', 'Tester']\n","quality_features = [\n","    'P01', 'Dark_Area_%', 'Defect_Area_%', 'Grain_Defect_Area_%',\n","    'Average_Life_Time', 'Sigma_Life_Time',\n","    'Resistivity', 'Wafer_Area', 'Vendor_name'\n","]\n","trained_features = model.feature_names_in_\n","\n","param_ranges = {\n","    'P02': (1, 6), 'P03': (1, 15),\n","    'P04': (1, 6), 'P05': (1, 15), 'P06': (1, 27),\n","    'Tester': (1, 20)\n","}\n","\n","# Select bottom 0.25% samples\n","threshold = np.percentile(data[\"Efficiency\"], 1)\n","samples = data[data[\"Efficiency\"] <= threshold].sample(n=100, random_state=RANDOM_STATE)\n","\n","results = []\n","\n","for idx, sample in samples.iterrows():\n","    quality_values = sample[quality_features]\n","    initial_eff = sample[\"Efficiency\"]\n","    initial_path = {key: sample[key] for key in equipment_features}\n","\n","    def objective(trial):\n","        path = {key: trial.suggest_int(key, *param_ranges[key]) for key in equipment_features}\n","        full_input = {**path, **quality_values.to_dict()}\n","        input_df = pd.DataFrame([full_input])[trained_features]\n","        return model.predict(input_df)[0]\n","\n","    study = optuna.create_study(\n","        direction=\"maximize\",\n","        sampler=optuna.samplers.TPESampler(n_startup_trials=20, seed=RANDOM_STATE)\n","    )\n","    start = time.time()\n","    study.optimize(objective, n_trials=300)\n","    elapsed = time.time() - start\n","\n","    best_path = study.best_params\n","    optimized_input = {**best_path, **quality_values.to_dict()}\n","    E_optimized = model.predict(pd.DataFrame([optimized_input])[trained_features])[0]\n","\n","    row = {\n","        \"Data Point\": idx,\n","        \"Initial Efficiency\": initial_eff,\n","        \"Optimized Efficiency\": E_optimized,\n","        \"Elapsed Time\": str(timedelta(seconds=int(elapsed)))\n","    }\n","\n","    for key in equipment_features:\n","        row[f\"Initial_{key}\"] = initial_path[key]\n","        row[f\"Best_{key}\"] = best_path[key]\n","\n","    for key in equipment_features:\n","        partial_path = initial_path.copy()\n","        partial_path[key] = best_path[key]\n","        partial_input = {**partial_path, **quality_values.to_dict()}\n","        E_partial = model.predict(pd.DataFrame([partial_input])[trained_features])[0]\n","        row[f\"ΔEff_{key}\"] = E_partial - initial_eff\n","\n","    results.append(row)\n","\n","# Save\n","df = pd.DataFrame(results)\n","os.makedirs(\"additional_analysis\", exist_ok=True)\n","df.to_excel(\"additional_analysis/Pathwise_Contribution_Trial3.xlsx\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qzadcPEg6xtv"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"250605_multiwafer","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}